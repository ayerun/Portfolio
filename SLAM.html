<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>SLAM</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
        <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script type="text/javascript" id="MathJax-script" async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
        </script>
        <script>
        window.MathJax = {
            tex: {
              tags: 'ams'
            }
          };
        </script>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li class="active"><a href="index.html">Projects</a></li>
							<li><a href="about.html">About</a></li>
							<li><a href="contact.html">Contact</a></li>
							<li><a href="Resume_Kumar.pdf" target="_blank" download>Resume</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/arun-kumar-102197/" target="_blank" class="icon brands alt fa-linkedin"><span class="label">Linkedin</span></a></li>
							<li><a href="https://github.com/ayerun" target="_blank" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<span class="date">January 2021 - March 2021</span>
									<h1>Differential Drive & SLAM from Scratch</h1>
                                    <p>Wrote all software for differential drive with (dead reckoning) odometry. Then, implemented an extended kalman filter for SLAM.</p>
                                </header>
                                
                                <div class="image main"><img src="images/SLAM/slam_cropped.png" alt="" /></div>
                                
								<h2>Overview</h2>
								<p> In this project, I took a Turtlebot3 Burger and removed all the preinstalled ROS software. 
                                    Then, I wrote, tested, and implemented my own C++ scripts for 2D transformations, differential drive, odometry, and SLAM. 
                                    This project served as a learning experience in ROS/C++ and demonstrates my knowledge of robotic software development.
                                    The only robotic software in this project that I did not code myself is the C code controlling the motors and lidar.<br/>
                                    -insert gif of turtlebot-
                                </p>

                                <h2>Setup</h2>
                                <h4>Robot Visualization</h4>
                                <p> I started this project by creating a ROS package (-insert link-) for robot visualization in Rviz. 
                                    This was the first step in the simulation process. 
                                    It was imperative to test my software in simulation prior to deploying new features onto the physical robot. 
                                    The controlled simulation environment simplifies the process of finding a correcting errors in my code. 
                                    This ROS package utilizes the URDF files written by the TurtleBot manufacturer to display the Robot in Rviz.<br/>
                                    -insert rviz pic-
                                </p>
								<h4>2D Tranformations</h4>
                                <p> Due to the math involved in differential drive and odometry, I decided to write a C++ library (-insert rigid2d link-) for 2D transformations. 
                                    The library provides data structures for 2D transformations, vectors, and twists.
                                    I wrote standard operator overload methods for addition, subtraction, and multiplication as well as methods for applying transformations to vectors and twists.
                                    The library was heavily tested (-insert link-). It serves as the backbone to all the software a created from this point.
								</p>

								<h2>Kinematics</h2>
								<p> Differential drive robots are controlled by a twist representing body velocity and angular velocity. 
                                    This means to control the robot, I needed to calculate the wheel velocities that achieve the desired twist. 
                                    I used the following diagram to derive the relationship between wheel velocities and body twist.
                                </p>
                                    <img class="image center" src="images/SLAM/kinematics.jpg" alt="" style="max-width: 30%"/><br/>
                                    <div class="align center">
                                        <p class="image center"><b>Figure 1.</b> 
                                            Reference frames for TurtleBot. X axes are in red and y axes are in greed. 
                                            Frame b is the body, r is the right wheel, and l is the left wheel.
                                        </p>
                                    </div>
                                <p>
                                    To start the derivation, I wrote the transformation matricies from the body to the wheels.<br/>
                                    $$T_{bl} = \begin{bmatrix} 1 & 0 & 0\\ 0 & 1 & D \\ 0 & 0 & 1 \end{bmatrix} \hspace{20mm}
                                    T_{br} = \begin{bmatrix} 1 & 0 & 0\\ 0 & 1 & -D \\ 0 & 0 & 1 \end{bmatrix}$$

                                    Then, I wrote the adjoint matricies between the body and wheels.<br/>
                                    $$A_{bl} = \begin{bmatrix} 1 & 0 & 0\\ D & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} \hspace{20mm}
                                    A_{br} = \begin{bmatrix} 1 & 0 & 0\\ -D & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$$
                                    $$A_{lb} = \begin{bmatrix} 1 & 0 & 0\\ -D & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} \hspace{20mm}
                                    A_{rb} = \begin{bmatrix} 1 & 0 & 0\\ D & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$$

                                    The following equation is used to relate twist in the wheel frame to the control.<br/>
                                    $$\begin{equation} \begin{bmatrix} \dot{x_i} \\ \dot{y_i} \end{bmatrix} = \begin{bmatrix} r\dot{&phi;}_i \\ 0 \end{bmatrix} \end{equation}$$
                                    r is the wheel radius<br/>
                                    \(\dot{&phi;}\) is the rotational velocity<br/>
                                    i is the wheel (l or r in this case)<br/><br/>

                                    Now, I can rewrite the body twist in the wheel frames.<br/>
                                    $$V_b = \begin{bmatrix} \dot{&theta;} \\ \dot{x} \\ \dot{y} \end{bmatrix} \hspace{20mm}
                                    V_i = \begin{bmatrix} \dot{&theta;} \\ r\dot{&phi;}_i \\ 0 \end{bmatrix}$$

                                    Since I am calculating controls, I want to solve for \(\dot{&phi;}_i\) in terms of D, r, \(\dot{&theta;}\), and \(\dot{x}\). 
                                    I used the following relationships to do so.<br/>
                                    $$V_l = A_{lb}V_b$$
                                    $$\begin{bmatrix} \dot{&theta;} \\ r\dot{&phi;}_l \\ 0 \end{bmatrix} = 
                                    \begin{bmatrix} 1 & 0 & 0\\ -D & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}
                                    \begin{bmatrix} \dot{&theta;} \\ \dot{x} \\ \dot{y} \end{bmatrix}$$
                                    $$\begin{equation} \mathbf{\dot{&phi;}_l = \frac{-D\dot{&theta;}+\dot{x}}{r}} \end{equation}$$
                                    <br/>
                                    $$V_r = A_{rb}V_b$$
                                    $$\begin{bmatrix} \dot{&theta;} \\ r\dot{&phi;}_r \\ 0 \end{bmatrix} = 
                                    \begin{bmatrix} 1 & 0 & 0\\ D & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}
                                    \begin{bmatrix} \dot{&theta;} \\ \dot{x} \\ \dot{y} \end{bmatrix}$$
                                    $$\begin{equation} \mathbf{\dot{&phi;}_r = \frac{D\dot{&theta;}+\dot{x}}{r}} \end{equation}$$

                                    With the rigid2d library, I implemented the kinematics for differential drive in a class called diff_drive (-insert link-).
                                    I wrote a ROS node called fake_turtle (-insert link-) that converts body velocities to wheel controls the publishes the controls.
                                    This allowed me to visualize the code in Rviz.
                                    (-insert gif of wheels moving-)
                                </p>
                                
                                <h2>Odometry</h2>
                                <p> To make the robot move in simulation, I needed to implement odometry. 
                                    There are two ways I could have done this, using IMU or dead reckoning. 
                                    The original TurtleBot software uses IMU which is often inaccurate due to sensor noise.
                                    I decided to use dead reckoning. 
                                    This method uses the change in wheel angles to calculate the robot's location.
                                    It performs best on flat planes with minimal slip.
                                    Since I typically drive the Turtlebot on a wood floor with good traction, this was the obvious choice.
                                    The first step to dead reckoning is obtaining the angular velocities of the wheels.
                                    Using the wheel encoders, I was able to measure the the angular velocities.
                                    Then I calculated the body twist by rearranging equations (2) and (3).

                                    $$\begin{equation} V_b = \begin{bmatrix} \dot{&theta;} \\ \dot{x} \\ \dot{y} \end{bmatrix} = 
                                    \begin{bmatrix} \frac{r(\dot{&phi;}_r-\dot{&phi;}_l)}{2D} \\ \frac{r(\dot{&phi;}_r+\dot{&phi;}_l)}{2} \\ 0 \end{bmatrix} \end{equation}$$
                                    
                                    The next step is integrating the twist \(V_b\) to find the change in position and orientation \(T_{bb'}\) where {b} is the original body frame and {b'} is the body frame after movement. 
                                    You could do this using matrix exponentials, but that is computationally expensive. 
                                    In 2D, there are more efficient methods. 
                                    When integrating the twist in 2D, there are two scenarios.<br/><br/>
                                    
                                    <b>Sceneraio 1: Translation without Rotation</b><br/>
                                    In the case \(V_b\) has no rotational component, \(T_{bb'}\) is a pure translation determined by the twist.
                                    $$V_b = \begin{bmatrix} 0 \\ \dot{x} \\ \dot{y} \end{bmatrix} \hspace{20mm}
                                    T_{bb'} = \begin{bmatrix} 1 & 0 & \dot{x}\\ 0 & 1 & \dot{y} \\ 0 & 0 & 1 \end{bmatrix}$$
                                    
                                    <b>Scenario 2: Translation with Rotation</b><br/>
                                    In the case \(V_b\) has translational and rotational comopnents, the math gets more complicated.
                                    For any two unit vectors (vector a and vector b) on a plane, there is a pure rotation that transforms vector a to vector b.
                                    Finding the center of rotation in the frame aligned with {b} is the first step to integrate the twist. 
                                    I will refer to frame {s} as the frame at the center of rotation in the orientation of frame {b}.
                                    I will refer to frame {s'} as the frame at the center of rotation in the orientation of frame {b'}.
                                    I determined the location of frame {s} using the adjoint.                                     
                                    $$\begin{bmatrix} 1 & 0 & 0\\ y_{s} & 1 & 0 \\ -x_{s} & 0 & 1 \end{bmatrix}
                                    \begin{bmatrix} &Delta; &theta; \\ &Delta; x_{b} \\ &Delta; y_{b} \end{bmatrix} = 
                                    \begin{bmatrix} \dot{&theta;} \\ 0 \\ 0 \end{bmatrix}$$
                                    Solving for \(x_{s}\) and \(y_{s}\) gives you \(T_{bs}\)
                                    $$T_{bs} = \begin{bmatrix} 1 & 0 & x_{s} \\ 0 & 1 & y_{s} \\ 0 & 0 & 1 \end{bmatrix}$$
                                    Next, I determined Tss' which is a pure rotation.
                                    $$T_{ss'} = \begin{bmatrix} \cos{\dot{&theta;}} & -\sin{\dot{&theta;}} & 0 \\ \sin{\dot{&theta;}} & \cos{\dot{&theta;}} & 0 \\ 0 & 0 & 1 \end{bmatrix}$$
                                    The last piece was determining \(T_{s'b'}\).
                                    Because frame {s} is the center of rotation between frame {b} and frame {b'}, we can think of frame {s} as the center of a circle with frames {b} and {b'} on the circle's circumference.
                                    Because frame {s} is oriented with {b} and frame {s'} is oriented with {b'}, \(T_{bs} = T_{s'b'}\). Finally, to solve for \(T_{bb'}\) we can use the following equation.
                                    $$\begin{equation} T_{bb'} = T_{bs}T_{ss'}T_{s'b'} \end{equation}$$
                                    Now that we characterized all robotic movements, we need to track the robot. This step is simple. 
                                    \(T_{wb}\) is the transformation from the world frame to the robot. 
                                    \(T_{bb'}\) is calculated everytime the robot moves. 
                                    To update the robots location, I used the following equation everytime the robot moved.
                                    $$\begin{equation} T_{wb'} = T_{wb}T_{bb'} \end{equation}$$
                                    $$T_{wb} = T_{wb'}$$
                                    -insert odometry experiments-
								</p>

								<h2>SLAM in Simulation</h2>
								<p>At this point in the project, I am able to teleoperate the TurtleBot and accurately track its location. 
                                    This is the framework for the real challenge in this project, SLAM using and Extended Kalman Filter (EKF). 
                                    To simplify the SLAM problem, I am using 10 cylindrical landmarks of equal radius. 
                                    I will use these landmarks for robot localization. 
                                    The robot will only be trained to regonize and use these landmarks in the EKF. 
                                </p>
                                <img class="image center" src="images/SLAM/SLAM_Pipeline.svg" alt="" style="max-width: 60%"/>
                                <div class="align center">
                                    <p class="image center"><b>Figure x.</b> 
                                        SLAM pipeline. Lidar data is the input. 
                                        Circle regression determines which data are landmarks. 
                                        Data association matches circles found in the lidar data with initialized landmarks from SLAM. 
                                        The associated data is then used the refine the SLAM estimate.
                                    </p>
                                </div>
                                <p><br/>To simplify the software developement required for thie pipeline. I started with SLAM in Simulation.
                                    This allowed me to develop and test the EKF prior to attempting circle regression and data association.
                                </p>
                                <h4>Simulation Setup</h4>
                                <p>Currently in simluation, the odometry data gives me the ground truth location of the robot. 
                                    This makes SLAM useless. 
                                    I needed to add noise to my simulation to make it more like the real world. 
                                    I added gaussian noise to the commanded twist and introduced slip to the wheel angels.
                                    This made my odometry data less accurate, as the robot moved. 
                                    Next, I added cylinders to the simulation environment to represent to landmarks.
                                    By adding gaussian noise to the ground truth landmark locations I was able to simulate the lidar data, circle regression, and data association in the SLAM pipeline. 
                                </p>
                                <h4>EKF SLAM Implementation</h4>
                                <p>With my simulation setup, I needed to use the noisy landmark locations to localize the robot in the simulation.
                                    By tracking the robot's ground truth location, odometry location, and SLAM location, as the robot moved in the environment I would be able to assess whether or not the algorithm was working.
                                    I split the algorithm into 3 parts.<br/><br/>

                                    <b>Initialization</b><br/>
                                    I started intializing the state of the environment.
                                    $$q_{t} = \begin{bmatrix} &theta; \\ x \\ y \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix} \hspace{20mm} 
                                    m_{t} = \begin{bmatrix} m_{{x}_{1}} \\ m_{{x}_{1}} \\ \textrm{...} \\ m_{{x}_{n}} \\ m_{{y}_{n}} \end{bmatrix} = 
                                    \begin{bmatrix} 0_{2n \textrm{ x } 1} \end{bmatrix} \hspace{20mm} 
                                    &xi;_{t} = g(&xi;_{t-1},u_{t},w_{t}) = \begin{bmatrix} q_{t} \\ m_{t} \end{bmatrix} = \begin{bmatrix} 0_{2n+3 \textrm{ x } 1} \end{bmatrix}$$
                                    \(q_{t}\) is the current robot state estimate<br/>
                                    \(m_{t}\) is the current landmark state estimate<br/>
                                    \(n\) is the max number of landmarks<br/>
                                    \(&xi;_{t}\) is the current state estimate of the entire environment<br/>
                                    \(g(&xi;_{t-1},u_{t},w_{t})\) is a transition function modeling the robot and map's movement<br/>
                                    \(u_{t}\) is the odometry model derived in the previous section<br/>
                                    \(w_{t}\) is the process noise in the system<br/><br/>


                                    Then, I initialized the state covariance matrix.
                                    $$&Sigma;_{0} = \begin{bmatrix} &Sigma;_{0,q} & 0_{3 \textrm{x} 2n} \\ 0_{2n \textrm{x} 3} & &Sigma;_{0,m} \end{bmatrix}$$
                                    \(&Sigma;_{0,q} \in \mathbb{R}^{3 \textrm{x} 3}\) is the covariance of the robot state<br/>
                                    \(&Sigma;_{0,m} \in \mathbb{R}^{2n \textrm{x} 2n}\) is the covariance of the landmark state matrix<br/><br/>
                                    \(&Sigma;_{0,q}\) was initialized to all zeros because the initial state of the robot is known.
                                    \(&Sigma;_{0,m}\) was initialized as a diagonal matrix with infinity on the diagonal because the landmark locations are unknown to the robot. 
                                    Lastly, I initialized the noise covariance matricies. These covariance matricies are parameters that can be tuned for better SLAM results.
                                    $$Q = \begin{bmatrix} 0.1 & 0 & 0 \\ 0 & 0.1 & 0 \\ 0 & 0 & 0.1 \end{bmatrix} \hspace{20mm}
                                    \bar{Q} = \begin{bmatrix} Q & 0_{3 \textrm{x} 2n} \\ 0_{2n \textrm{x} 3} & 0_{2n \textrm{x} 2n} \end{bmatrix} \hspace{20mm}
                                    R = \begin{bmatrix} 0.1 & 0 \\ 0 & 0.1 \end{bmatrix}$$
                                    Q is the process noise covariance matrix<br/>
                                    \(\bar{Q}\) is the process noise expanded to fill the whole state<br/>
                                    R is the sensor noise covariance matrix<br/><br/>

                                    <b>Predicition</b><br/>
                                    The first step to predicition is updating the state estimate using odometry.
                                    $$\begin{equation} &xi;^{-}_{t} = g(&xi;_{t-1},u_{t},0) \end{equation}$$
                                    Then, propagate the uncertainty using the linearized state transition model.
                                    $$\begin{equation} &Sigma;^{-}_{t} = A_{t}&Sigma;_{t-1}A^{T}_{t}+\bar{Q} \end{equation}$$
                                    The EKF uses a state transition model, \(g(&xi;_{t-1},u_{t},0)\), that is linearized about the current state estimate. 
                                    In equation (3), \(A_{t}\) is the deviative g with respect to the state, \(g'(&xi;_{t-1},u_{t},0)\), used in the linearization. 
                                    \(A_{t}\) has two equations.<br/><br/>
                                    No Rotation:<br/>
                                    $$\begin{equation} A_{t} = g'(&xi;_{t-1},u_{t},0) = I + 
                                    \begin{bmatrix} P_{1} & 0_{3 \textrm{x} 2n} \\ 0_{2n \textrm{x} 3} & 0_{2n \textrm{x} 2n} \end{bmatrix} \end{equation}$$
                                    $$P_{1} = \begin{bmatrix} 0 & 0 & 0 \\ -&Delta;x_{t}\sin(&theta;_{t-1}) & 0 & 0 \\ &Delta;x_{t}\cos(&theta;_{t-1}) & 0 & 0 \end{bmatrix}$$
                                    Rotation:<br/>
                                    $$\begin{equation} A_{t} = g'(&xi;_{t-1},u_{t},0) = I + 
                                    \begin{bmatrix} P_{2} & 0_{3 \textrm{x} 2n} \\ 0_{2n \textrm{x} 3} & 0_{2n \textrm{x} 2n} \end{bmatrix}\end{equation}$$
                                    $$P_{2} = \begin{bmatrix} 0 & 0 & 0 \\ 
                                    -\frac{&Delta;x_{t}}{&Delta;&theta;_{t}}\cos(&theta;_{t-1})+\frac{&Delta;x_{t}}{&Delta;&theta;_{t}}\cos(&theta;_{t-1}+&Delta;&theta;_{t}) & 0 & 0 \\ 
                                    -\frac{&Delta;x_{t}}{&Delta;&theta;_{t}}\sin(&theta;_{t-1})+\frac{&Delta;x_{t}}{&Delta;&theta;_{t}}\sin(&theta;_{t-1}+&Delta;&theta;_{t}) & 0 & 0 \end{bmatrix}$$
                                    
                                    
                                    <br/><b>Update</b><br/>
                                    The update step of the EKF is a loop for each measurement.
                                    In this explanation, we will refer to the measurement as i and the associated landmark as j.<br/><br/>

                                    1) Calculate the theoretical measurement using the current state estimate.
                                    $$\begin{equation} \hat{z}^{i}_{t} = h_{j}(&xi;^{-}_{t}) \end{equation}$$
                                    $$h_{j}(&xi;^{-}_{t}) = \begin{bmatrix} \sqrt{(m_{x,j}-x_{t})^{2}+(m_{y,j}-y_{t})^{2}} \\ \textrm{atan2}(m_{y,j}-y_{t},m_{x,j}-x_{t})-&theta;_{t} \end{bmatrix}$$
                                    \(\hat{z}^{i}_{t}\) is the theoretical range and bearing from the robot to landmark<br/><br/>
                                    
                                    2) Calculate the Kalman gain using the linearized measurement model.
                                    $$\begin{equation} K_{i} = &Sigma;^{-}_{t}H^{T}_{j}(H_{j}&Sigma;^{-}_{t}H^{T}_{j}+R)^{-1} \end{equation}$$
                                    $$H_{j} = h_{j}'(&xi;^{-}_{t}) = 
                                    \begin{bmatrix} 0 & \frac{-&delta;_{x}}{\sqrt{d}} & \frac{-&delta;_{y}}{\sqrt{d}} & 0_{1 \textrm{ x } 2(j-1)} & \frac{&delta;_{x}}{\sqrt{d}} & \frac{&delta;_{y}}{\sqrt{d}} & 0_{1 \textrm{ x } 2n-2j} \\ 
                                    -1 & \frac{&delta;_{y}}{d} & \frac{-&delta;_{x}}{d} & 0_{1 \textrm{ x } 2(j-1)} & \frac{-&delta;_{y}}{d} & \frac{&delta;_{x}}{d} & 0_{1 \textrm{ x } 2n-2j} \end{bmatrix}$$
                                    $$&delta;_{x} = m_{x,j}-x_{t}$$
                                    $$&delta;_{y} = m_{y,j}-y_{t}$$
                                    $$d = &delta;_{x}^2+&delta;_{y}^2$$<br/><br/>

                                    3) Calculate the posterior state update
                                    $$\begin{equation} &xi;_{t} = &xi;^{-}_{t}+K_{i}(z^{i}_{t}-\hat{z}^{i}_{t}) \end{equation}$$
                                    \(z^{i}_{t}\) is the measured range and bearing from the robot to landmark<br/><br/>

                                    4) Calculate the posterior covariance
                                    $$ \begin{equation} &Sigma;_{t} = (I-K_{i}H_{j})&Sigma;^{-}_{t} \end{equation} $$

                                    5) Update state and covariance for next measurement (i)
                                    $$ &Sigma;_{t}^{-} = &Sigma;_{t} $$
                                    $$ &xi;_{t}^{-} = &xi;_{t} $$
                                </p>

								<h2>Future Work</h2>
								<p>
                                </p>

                                <h1><a href="https://github.com/ayerun/Robotic_3D_Scanner" target="_blank">-View Full Source Code-</a></h1>
							</section>

					</div>

				<!-- Copyright -->
					<div id="copyright">
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>